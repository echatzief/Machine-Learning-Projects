{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "    <h1>Principal Component Analysis</h1>\n",
    "    <strong>Team G</strong>\n",
    "    <div>Evangelou Sotiris 2159</div>\n",
    "    <div>Kalais Konstantinos 2146</div>\n",
    "    <div>Chatziefremidis Leuteris 2209</div>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\triangleright$ Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\triangleright$ Read the data and preprocess them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the first dataset\n",
    "dfSetFirst = pd.read_csv('./analysis_greek_regions.csv',usecols=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])\n",
    "\n",
    "#Replace missing values with the mean of that column\n",
    "cols = dfSetFirst.columns.tolist()\n",
    "dfSetFirst[cols] = dfSetFirst[cols].fillna(dfSetFirst[cols].median())\n",
    "\n",
    "#Drop the NAN values\n",
    "dfSetFirst = dfSetFirst.dropna(axis='columns')\n",
    "\n",
    "#Read the second dataset\n",
    "cols = [k for k in range(1,27)]\n",
    "dfSetSec = pd.read_csv('./correlation_matrix_job_performance.csv',usecols=cols)\n",
    "\n",
    "#Replace missing values with the mean of that column\n",
    "cols = dfSetSec.columns.tolist()\n",
    "dfSetSec[cols] = dfSetSec[cols].fillna(dfSetSec[cols].median())\n",
    "\n",
    "#Drop the NAN values\n",
    "dfSetSec = dfSetSec.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\triangleright$ First Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSetFirst.head()\n",
    "firstFeatureCount = len(dfSetFirst.columns.tolist())\n",
    "dfSetFirst.to_csv('greek_regions_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\triangleright$ Second Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSetSec.head()\n",
    "secFeatureCount = len(dfSetSec.columns.tolist())\n",
    "dfSetSec.to_csv('job_performance_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\triangleright$ Standarizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether to standardize the data prior to a PCA on the covariance matrix depends on the measurement scales of the original features. Since PCA yields a feature subspace that maximizes the variance along the axes, it makes sense to standardize the data, especially, if it was measured on different scales. Although, all features in the Iris dataset were measured in centimeters, let us continue with the transformation of the data onto unit scale (mean=0 and variance=1), which is a requirement for the optimal performance of many machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Standarize the first dataset\n",
    "firstDataset = np.array(dfSetFirst)\n",
    "copyOfFirstData = firstDataset\n",
    "firstDataset = StandardScaler().fit_transform(firstDataset)\n",
    "\n",
    "\n",
    "#Standarize the second dataset\n",
    "secDataset = np.array(dfSetSec)\n",
    "copyOfSecData = secDataset\n",
    "secDataset = StandardScaler().fit_transform(secDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\triangleright$ Covariance matrix of each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classic approach to PCA is to perform the eigendecomposition on the covariance matrix Σ, which is a d×d matrix where each element represents the covariance between two features. The covariance between two features is calculated as follows:\n",
    "\n",
    "$$ \\sigma_{jk} = \\frac{1}{n-1}\\sum_{i = 1}^{N}(x_{ij} - \\overline{x}_{j})(x_{ik} - \\overline{x}_{k})$$\n",
    "\n",
    "We can summarize the calculation of the covariance matrix via the following matrix equation:\n",
    "\n",
    "$$ \\sum = \\frac{1}{n-1}((X - \\overline{x})^{T}(X - \\overline{x}))$$\n",
    "\n",
    "The mean vector is a d-dimensional vector where each value in this vector represents the sample mean of a feature column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the numpy covariance module\n",
    "\n",
    "firstDatasetCovMatrix =  np.cov(firstDataset.T)\n",
    "secDatasetCovMatrix = np.cov(secDataset.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\triangleright$ Retrieve eigenvalues and eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvectors and eigenvalues of a covariance (or correlation) matrix represent the \"core\" of a PCA: The eigenvectors (principal components) determine the directions of the new feature space, and the eigenvalues determine their magnitude. In other words, the eigenvalues explain the variance of the data along the new feature axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues of first dataset: \n",
      "[1.23716512e+01 1.11552676e+00 6.74313778e-01 4.73174607e-01\n",
      " 2.78618576e-01 1.88640082e-01 1.12027621e-01 9.88723570e-02\n",
      " 6.22891835e-02 4.54223333e-02 3.02768044e-02 1.51758542e-02\n",
      " 2.25493430e-03 8.75521085e-03 6.87164940e-03]\n",
      "\n",
      "Eigenvectors of first dataset: \n",
      "[[ 0.24369803  0.17098971  0.58772352  0.14911412 -0.1436111   0.16993678\n",
      "   0.15139091  0.04702509 -0.09509343  0.11979808 -0.16980116 -0.5670161\n",
      "  -0.21627772 -0.20317871  0.0854104 ]\n",
      " [ 0.28008186 -0.05039915  0.10914117  0.09025968 -0.05061439 -0.19922795\n",
      "   0.40682538  0.10978293  0.0024308   0.54526152  0.34548583  0.08455457\n",
      "   0.16630718  0.36028801 -0.31281177]\n",
      " [ 0.28188972 -0.04105528 -0.06217544 -0.21613255 -0.06364745 -0.11054151\n",
      "   0.10193688 -0.32418732 -0.01558573  0.1014236   0.22509705  0.10633383\n",
      "   0.24644292 -0.77595354 -0.0342253 ]\n",
      " [ 0.26895465  0.13414163  0.12268233 -0.15777876  0.1541007  -0.37918249\n",
      "  -0.61785438 -0.39102146 -0.18573154  0.0966369  -0.0623806  -0.12471719\n",
      "  -0.06789018  0.2179876  -0.22835901]\n",
      " [ 0.27757678 -0.05110102  0.09344281 -0.01394419  0.13826314 -0.43720918\n",
      "   0.30087735  0.14413929 -0.07259598 -0.15653206 -0.67744558  0.27197159\n",
      "   0.13409641 -0.00968139  0.09535645]\n",
      " [ 0.25971893 -0.17181756 -0.213677    0.45703501 -0.07364859 -0.0823634\n",
      "   0.12227355 -0.1654014  -0.52338028 -0.42321748  0.26513665 -0.15322134\n",
      "   0.06667363  0.12110313  0.16746386]\n",
      " [ 0.26416648  0.04819129 -0.04552463 -0.40821487  0.29760261  0.29864603\n",
      "  -0.12713249  0.50798384 -0.51120837  0.08247158  0.11544025  0.10137753\n",
      "  -0.02259109 -0.02910774  0.11881813]\n",
      " [ 0.27906367 -0.05855422 -0.17784069 -0.14736847  0.16028599  0.15402848\n",
      "   0.10362737  0.14850917  0.28499935 -0.44270981 -0.0275372  -0.33264779\n",
      "   0.07088374  0.00912507 -0.62402155]\n",
      " [ 0.26332617 -0.0326065  -0.23183161 -0.31881825 -0.2251064   0.47264148\n",
      "   0.20638539 -0.48998632 -0.00666827  0.11970607 -0.28272732  0.01917335\n",
      "  -0.01192317  0.31343846  0.15620048]\n",
      " [ 0.27869845 -0.05310836 -0.04656986 -0.0182995   0.39993051 -0.09409386\n",
      "  -0.06069778  0.0260346   0.49254582  0.01977271  0.19130306 -0.25843829\n",
      "   0.19432641  0.12323417  0.58695314]\n",
      " [ 0.24743769 -0.04382118 -0.24657143  0.61539721  0.24474211  0.32744628\n",
      "  -0.25267883  0.02278066  0.08304916  0.33492484 -0.25552697  0.164374\n",
      "  -0.04006564 -0.18507939 -0.13643123]\n",
      " [ 0.25200374  0.18886107  0.4862152   0.10912322 -0.20471081  0.27154797\n",
      "  -0.20872703  0.00598949  0.17011869 -0.33295115  0.15283113  0.47367175\n",
      "   0.30272655  0.11872426  0.00263073]\n",
      " [ 0.25302256  0.00381045 -0.31761492 -0.02819794 -0.7031509  -0.1846072\n",
      "  -0.30193996  0.39705726  0.12953301  0.07952373 -0.07410049 -0.12516173\n",
      "   0.03639264 -0.02047287  0.10471278]\n",
      " [ 0.28702361 -0.03810755 -0.01059734 -0.02893905 -0.00210193 -0.11167863\n",
      "   0.10013626 -0.01410154  0.1978263  -0.12963332  0.20420857  0.30313698\n",
      "  -0.83649518 -0.03738507  0.04310219]\n",
      " [ 0.00748238  0.93151498 -0.28557735  0.07965125  0.05803587 -0.06947076\n",
      "   0.17936473 -0.01822867 -0.00768479 -0.03773003  0.03946365  0.00235399\n",
      "   0.00764586 -0.00114125  0.0228358 ]]\n",
      "\n",
      "Eigenvalues of second dataset: \n",
      "[5.63179179e+00 2.89684201e+00 1.97763390e+00 1.26664450e+00\n",
      " 6.65163182e-01 4.97212682e-01 3.63659238e-01 2.21154632e-01\n",
      " 2.00039980e-01 5.41856921e-04 1.45392817e-01 5.05256385e-02\n",
      " 8.33977742e-02]\n",
      "\n",
      "Eigenvectors of second dataset: \n",
      "[[-0.04223181 -0.50287759  0.06352022 -0.30292975  0.04398722  0.52616423\n",
      "  -0.03585837 -0.25019878 -0.50519975  0.04045505  0.17116905 -0.07811624\n",
      "   0.12081408]\n",
      " [-0.04547714 -0.42708002 -0.40404954 -0.00698951  0.33041801 -0.00235881\n",
      "   0.44352912 -0.25504146  0.52006379  0.006357    0.08364132 -0.01363101\n",
      "  -0.05996103]\n",
      " [-0.27594635 -0.37458428  0.06638405  0.13695376 -0.07702491 -0.59024711\n",
      "  -0.1192655   0.01152056 -0.12630752 -0.38541973  0.28327645 -0.11347289\n",
      "   0.3661584 ]\n",
      " [ 0.27520253 -0.32243976 -0.14534649  0.35786694  0.12639871 -0.00912189\n",
      "   0.21079416  0.63161719 -0.3308946  -0.01379877 -0.03438363 -0.09841894\n",
      "  -0.30185652]\n",
      " [-0.35598909 -0.0926953   0.24549826  0.25639019  0.10096     0.20199643\n",
      "  -0.40004565 -0.05329199  0.22961943 -0.13994692  0.22710776 -0.21476179\n",
      "  -0.59564352]\n",
      " [-0.38461231 -0.02930216  0.04880418  0.17751338  0.19634251  0.42277716\n",
      "  -0.06040039  0.37267956  0.2136896  -0.16435736 -0.37934046  0.00097238\n",
      "   0.49083197]\n",
      " [ 0.41941457  0.00086945  0.11396236  0.07800692 -0.03106298  0.0280104\n",
      "  -0.06181907 -0.13594791  0.15662471 -0.00164022 -0.14398194 -0.83533646\n",
      "   0.19471376]\n",
      " [ 0.42316967 -0.09081372  0.00900635 -0.09793018 -0.00815128  0.09836331\n",
      "  -0.1410895  -0.13446616  0.07175492 -0.77065686 -0.25902749  0.27061547\n",
      "  -0.12605933]\n",
      " [-0.10524166 -0.17821675  0.54622775  0.19468327 -0.49165309  0.0528891\n",
      "   0.55446122 -0.12120511  0.07373157 -0.01539922 -0.1903479   0.06388772\n",
      "  -0.09094649]\n",
      " [-0.21325696  0.14046696  0.16534814 -0.70401039  0.13137774 -0.09818201\n",
      "   0.29240062  0.35059374  0.02368834 -0.24575883  0.02787815 -0.28098411\n",
      "  -0.18925685]\n",
      " [ 0.12689147 -0.05676281  0.55170924  0.03777071  0.70476673 -0.2442814\n",
      "   0.00362733 -0.1479834  -0.09623304  0.16863262 -0.18887317  0.15091945\n",
      "   0.02091685]\n",
      " [-0.09110891  0.4979799  -0.06870535  0.33588896  0.24799633  0.1760113\n",
      "   0.40350809 -0.22877934 -0.30079591 -0.34598581  0.30259911 -0.11180742\n",
      "   0.0654291 ]\n",
      " [ 0.36561298  0.0062377   0.31088367 -0.0256336  -0.0048718   0.20390544\n",
      "   0.0129533   0.28834464  0.33920081  0.01712773  0.6593372   0.18893137\n",
      "   0.24145345]]\n"
     ]
    }
   ],
   "source": [
    "#For the first dataset \n",
    "firstEigValsCov,firstEigVecCov = np.linalg.eig(firstDatasetCovMatrix)\n",
    "print(\"Eigenvalues of first dataset: \")\n",
    "print(firstEigValsCov)\n",
    "print()\n",
    "print(\"Eigenvectors of first dataset: \")\n",
    "print(firstEigVecCov)\n",
    "print()\n",
    "\n",
    "#For the second dataset\n",
    "secEigValsCov,secEigVecCov = np.linalg.eig(secDatasetCovMatrix)\n",
    "print(\"Eigenvalues of second dataset: \")\n",
    "print(secEigValsCov)\n",
    "print()\n",
    "print(\"Eigenvectors of second dataset: \")\n",
    "print(secEigVecCov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\triangleright$ Correlation matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix typically used instead of the covariance matrix. However, the eigendecomposition of the covariance matrix (if the input data was standardized) yields the same results as a eigendecomposition on the correlation matrix, since the correlation matrix can be understood as the normalized covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues of first dataset: \n",
      "[1.19850371e+01 1.08066655e+00 6.53241473e-01 4.58387901e-01\n",
      " 2.69911745e-01 1.82745079e-01 1.08526758e-01 9.57825958e-02\n",
      " 6.03426465e-02 4.40028854e-02 2.93306543e-02 1.47016088e-02\n",
      " 2.18446761e-03 8.48161051e-03 6.65691035e-03]\n",
      "\n",
      "Eigenvectors of first dataset: \n",
      "[[ 0.24369803  0.17098971  0.58772352  0.14911412 -0.1436111   0.16993678\n",
      "   0.15139091 -0.04702509  0.09509343 -0.11979808 -0.16980116 -0.5670161\n",
      "  -0.21627772 -0.20317871  0.0854104 ]\n",
      " [ 0.28008186 -0.05039915  0.10914117  0.09025968 -0.05061439 -0.19922795\n",
      "   0.40682538 -0.10978293 -0.0024308  -0.54526152  0.34548583  0.08455457\n",
      "   0.16630718  0.36028801 -0.31281177]\n",
      " [ 0.28188972 -0.04105528 -0.06217544 -0.21613255 -0.06364745 -0.11054151\n",
      "   0.10193688  0.32418732  0.01558573 -0.1014236   0.22509705  0.10633383\n",
      "   0.24644292 -0.77595354 -0.0342253 ]\n",
      " [ 0.26895465  0.13414163  0.12268233 -0.15777876  0.1541007  -0.37918249\n",
      "  -0.61785438  0.39102146  0.18573154 -0.0966369  -0.0623806  -0.12471719\n",
      "  -0.06789018  0.2179876  -0.22835901]\n",
      " [ 0.27757678 -0.05110102  0.09344281 -0.01394419  0.13826314 -0.43720918\n",
      "   0.30087735 -0.14413929  0.07259598  0.15653206 -0.67744558  0.27197159\n",
      "   0.13409641 -0.00968139  0.09535645]\n",
      " [ 0.25971893 -0.17181756 -0.213677    0.45703501 -0.07364859 -0.0823634\n",
      "   0.12227355  0.1654014   0.52338028  0.42321748  0.26513665 -0.15322134\n",
      "   0.06667363  0.12110313  0.16746386]\n",
      " [ 0.26416648  0.04819129 -0.04552463 -0.40821487  0.29760261  0.29864603\n",
      "  -0.12713249 -0.50798384  0.51120837 -0.08247158  0.11544025  0.10137753\n",
      "  -0.02259109 -0.02910774  0.11881813]\n",
      " [ 0.27906367 -0.05855422 -0.17784069 -0.14736847  0.16028599  0.15402848\n",
      "   0.10362737 -0.14850917 -0.28499935  0.44270981 -0.0275372  -0.33264779\n",
      "   0.07088374  0.00912507 -0.62402155]\n",
      " [ 0.26332617 -0.0326065  -0.23183161 -0.31881825 -0.2251064   0.47264148\n",
      "   0.20638539  0.48998632  0.00666827 -0.11970607 -0.28272732  0.01917335\n",
      "  -0.01192317  0.31343846  0.15620048]\n",
      " [ 0.27869845 -0.05310836 -0.04656986 -0.0182995   0.39993051 -0.09409386\n",
      "  -0.06069778 -0.0260346  -0.49254582 -0.01977271  0.19130306 -0.25843829\n",
      "   0.19432641  0.12323417  0.58695314]\n",
      " [ 0.24743769 -0.04382118 -0.24657143  0.61539721  0.24474211  0.32744628\n",
      "  -0.25267883 -0.02278066 -0.08304916 -0.33492484 -0.25552697  0.164374\n",
      "  -0.04006564 -0.18507939 -0.13643123]\n",
      " [ 0.25200374  0.18886107  0.4862152   0.10912322 -0.20471081  0.27154797\n",
      "  -0.20872703 -0.00598949 -0.17011869  0.33295115  0.15283113  0.47367175\n",
      "   0.30272655  0.11872426  0.00263073]\n",
      " [ 0.25302256  0.00381045 -0.31761492 -0.02819794 -0.7031509  -0.1846072\n",
      "  -0.30193996 -0.39705726 -0.12953301 -0.07952373 -0.07410049 -0.12516173\n",
      "   0.03639264 -0.02047287  0.10471278]\n",
      " [ 0.28702361 -0.03810755 -0.01059734 -0.02893905 -0.00210193 -0.11167863\n",
      "   0.10013626  0.01410154 -0.1978263   0.12963332  0.20420857  0.30313698\n",
      "  -0.83649518 -0.03738507  0.04310219]\n",
      " [ 0.00748238  0.93151498 -0.28557735  0.07965125  0.05803587 -0.06947076\n",
      "   0.17936473  0.01822867  0.00768479  0.03773003  0.03946365  0.00235399\n",
      "   0.00764586 -0.00114125  0.0228358 ]]\n",
      "\n",
      "Eigenvalues of second dataset: \n",
      "[5.22952095e+00 2.68992473e+00 1.83637433e+00 1.17616989e+00\n",
      " 6.17651526e-01 4.61697491e-01 3.37683578e-01 2.05357872e-01\n",
      " 1.85751410e-01 5.03152855e-04 1.35007615e-01 4.69166643e-02\n",
      " 7.74407903e-02]\n",
      "\n",
      "Eigenvectors of second dataset: \n",
      "[[-0.04223181 -0.50287759  0.06352022 -0.30292975  0.04398722  0.52616423\n",
      "  -0.03585837 -0.25019878 -0.50519975  0.04045505  0.17116905 -0.07811624\n",
      "   0.12081408]\n",
      " [-0.04547714 -0.42708002 -0.40404954 -0.00698951  0.33041801 -0.00235881\n",
      "   0.44352912 -0.25504146  0.52006379  0.006357    0.08364132 -0.01363101\n",
      "  -0.05996103]\n",
      " [-0.27594635 -0.37458428  0.06638405  0.13695376 -0.07702491 -0.59024711\n",
      "  -0.1192655   0.01152056 -0.12630752 -0.38541973  0.28327645 -0.11347289\n",
      "   0.3661584 ]\n",
      " [ 0.27520253 -0.32243976 -0.14534649  0.35786694  0.12639871 -0.00912189\n",
      "   0.21079416  0.63161719 -0.3308946  -0.01379877 -0.03438363 -0.09841894\n",
      "  -0.30185652]\n",
      " [-0.35598909 -0.0926953   0.24549826  0.25639019  0.10096     0.20199643\n",
      "  -0.40004565 -0.05329199  0.22961943 -0.13994692  0.22710776 -0.21476179\n",
      "  -0.59564352]\n",
      " [-0.38461231 -0.02930216  0.04880418  0.17751338  0.19634251  0.42277716\n",
      "  -0.06040039  0.37267956  0.2136896  -0.16435736 -0.37934046  0.00097238\n",
      "   0.49083197]\n",
      " [ 0.41941457  0.00086945  0.11396236  0.07800692 -0.03106298  0.0280104\n",
      "  -0.06181907 -0.13594791  0.15662471 -0.00164022 -0.14398194 -0.83533646\n",
      "   0.19471376]\n",
      " [ 0.42316967 -0.09081372  0.00900635 -0.09793018 -0.00815128  0.09836331\n",
      "  -0.1410895  -0.13446616  0.07175492 -0.77065686 -0.25902749  0.27061547\n",
      "  -0.12605933]\n",
      " [-0.10524166 -0.17821675  0.54622775  0.19468327 -0.49165309  0.0528891\n",
      "   0.55446122 -0.12120511  0.07373157 -0.01539922 -0.1903479   0.06388772\n",
      "  -0.09094649]\n",
      " [-0.21325696  0.14046696  0.16534814 -0.70401039  0.13137774 -0.09818201\n",
      "   0.29240062  0.35059374  0.02368834 -0.24575883  0.02787815 -0.28098411\n",
      "  -0.18925685]\n",
      " [ 0.12689147 -0.05676281  0.55170924  0.03777071  0.70476673 -0.2442814\n",
      "   0.00362733 -0.1479834  -0.09623304  0.16863262 -0.18887317  0.15091945\n",
      "   0.02091685]\n",
      " [-0.09110891  0.4979799  -0.06870535  0.33588896  0.24799633  0.1760113\n",
      "   0.40350809 -0.22877934 -0.30079591 -0.34598581  0.30259911 -0.11180742\n",
      "   0.0654291 ]\n",
      " [ 0.36561298  0.0062377   0.31088367 -0.0256336  -0.0048718   0.20390544\n",
      "   0.0129533   0.28834464  0.33920081  0.01712773  0.6593372   0.18893137\n",
      "   0.24145345]]\n"
     ]
    }
   ],
   "source": [
    "#For the first dataset\n",
    "corrFirstDataset = np.corrcoef(firstDataset.T)\n",
    "firstEigVals,firstEigVec = np.linalg.eig(corrFirstDataset)\n",
    "print(\"Eigenvalues of first dataset: \")\n",
    "print(firstEigVals)\n",
    "print()\n",
    "print(\"Eigenvectors of first dataset: \")\n",
    "print(firstEigVec)\n",
    "print()\n",
    "\n",
    "#For the second dataset\n",
    "corrSecDataset = np.corrcoef(secDataset.T)\n",
    "secEigVals,secEigVec = np.linalg.eig(corrSecDataset)\n",
    "print(\"Eigenvalues of second dataset: \")\n",
    "print(secEigVals)\n",
    "print()\n",
    "print(\"Eigenvectors of second dataset: \")\n",
    "print(secEigVec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result \n",
    "We can see that the eigenvectors from the correlation matrix that came from standarized data is equal to the \n",
    "eigenvectors of the covariance matrix.So as we said before the correlation matrix can be understood as the normalized covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\triangleright$ Singular Vector Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the eigendecomposition of the covariance or correlation matrix may be more intuitiuve, most PCA implementations perform a Singular Vector Decomposition (SVD) to improve the computational efficiency. So, let us perform an SVD to confirm that the result are indeed the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For the first dataset\n",
    "uFirst,sFirst,vFirst = np.linalg.svd(firstDataset.T)\n",
    "\n",
    "#For the second dataset\n",
    "uSec,sSec,vSec = np.linalg.svd(secDataset.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\triangleright$ Selecting Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to decide which eigenvector(s) can be dropped without losing too much information for the construction of lower-dimensional subspace, we need to inspect the corresponding eigenvalues: The eigenvectors with the lowest eigenvalues bear the least information about the distribution of the data; those are the ones can be dropped.\n",
    "In order to do so, the common approach is to rank the eigenvalues from highest to lowest in order choose the top k eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues in descending order of first Dataset:\n",
      "12.371651217198405\n",
      "1.1155267594176779\n",
      "0.6743137783538276\n",
      "0.473174607357753\n",
      "0.2786185756149344\n",
      "0.18864008204792426\n",
      "0.11202762077104096\n",
      "0.09887235697350455\n",
      "0.062289183473135716\n",
      "0.04542233332582816\n",
      "0.030276804447769628\n",
      "0.015175854211391792\n",
      "0.008755210845573028\n",
      "0.006871649398538567\n",
      "0.0022549343046290265\n",
      "\n",
      "Eigenvalues in descending order of second Dataset:\n",
      "5.631791792487169\n",
      "2.896842013053831\n",
      "1.977633897189647\n",
      "1.266644497565375\n",
      "0.6651631815344993\n",
      "0.4972126823374733\n",
      "0.36365923796626126\n",
      "0.22115463180422543\n",
      "0.2000399798056026\n",
      "0.1453928166813932\n",
      "0.08339777418993613\n",
      "0.05052563846371935\n",
      "0.0005418569208747768\n"
     ]
    }
   ],
   "source": [
    "#For the first dataset\n",
    "\n",
    "#Make a list of (eigenvalue, eigenvector) tuples\n",
    "eigPairFirst = [(np.abs(firstEigValsCov[i]), firstEigVecCov[:,i]) for i in range(len(firstEigValsCov))]\n",
    "eigPairFirst.sort()\n",
    "eigPairFirst.reverse()\n",
    "print('Eigenvalues in descending order of first Dataset:')\n",
    "for i in eigPairFirst:\n",
    "    print(i[0])\n",
    "    \n",
    "\n",
    "#For the second dataset\n",
    "\n",
    "#Make a list of (eigenvalue, eigenvector) tuples\n",
    "eigPairSec = [(np.abs(secEigValsCov[i]), secEigVecCov[:,i]) for i in range(len(secEigValsCov))]\n",
    "eigPairSec.sort()\n",
    "eigPairSec.reverse()\n",
    "print()\n",
    "print('Eigenvalues in descending order of second Dataset:')\n",
    "for i in eigPairSec:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After sorting the eigenpairs, the next question is \"how many principal components are we going to choose for our new feature subspace?\" A useful measure is the so-called \"explained variance,\" which can be calculated from the eigenvalues. The explained variance tells us how much information (variance) can be attributed to each of the principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\triangleright$ Create the array for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the first dataset\n",
    "\n",
    "#Create the W array and get Y  = X * W\n",
    "#We get only 2 pairs\n",
    "matrixFirst = np.hstack((eigPairFirst[0][1].reshape(firstFeatureCount,1)\n",
    "                      ,eigPairFirst[1][1].reshape(firstFeatureCount,1)))\n",
    "\n",
    "#For the second dataset\n",
    "\n",
    "#Create the W array and get Y  = X * W\n",
    "#We get only 2 pairs\n",
    "matrixSec = np.hstack((eigPairSec[0][1].reshape(secFeatureCount,1)\n",
    "                      ,eigPairSec[1][1].reshape(secFeatureCount,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\triangleright$ First array after transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.216585</td>\n",
       "      <td>-0.332773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.217486</td>\n",
       "      <td>-1.035836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.292386</td>\n",
       "      <td>0.616760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.427211</td>\n",
       "      <td>-0.472625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.031488</td>\n",
       "      <td>-0.978573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0 -2.216585 -0.332773\n",
       "1  1.217486 -1.035836\n",
       "2  3.292386  0.616760\n",
       "3 -1.427211 -0.472625\n",
       "4  7.031488 -0.978573"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstDatasetTransform = firstDataset.dot(matrixFirst)\n",
    "pd.DataFrame(firstDatasetTransform).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\triangleright$ Second array after transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.034514</td>\n",
       "      <td>0.062367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.467512</td>\n",
       "      <td>-2.500458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.474475</td>\n",
       "      <td>-1.925124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.369840</td>\n",
       "      <td>-1.611009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.997501</td>\n",
       "      <td>-1.448503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0 -0.034514  0.062367\n",
       "1 -0.467512 -2.500458\n",
       "2 -0.474475 -1.925124\n",
       "3 -2.369840 -1.611009\n",
       "4  1.997501 -1.448503"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secDatasetTransform = secDataset.dot(matrixSec)\n",
    "pd.DataFrame(secDatasetTransform).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "<a href=\"https://plot.ly/ipython-notebooks/principal-component-analysis/?fbclid=IwAR26i-Y8g1PkalUA9OMrnr7S7IoXSRgme7pLcFCLULCvfY4uWZ5oi5MGTn4\">Principal Component Analysis</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
